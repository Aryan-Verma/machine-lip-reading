{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "#from train_lstm_oh import build_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers.wrappers import TimeDistributed, Bidirectional\n",
    "from keras.layers.recurrent import GRU,LSTM\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import ZeroPadding3D, Conv2D\n",
    "from keras import regularizers\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Lambda, Dropout, Flatten, Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = os.getcwd()\n",
    "DATA_PATH = CURRENT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "x_path = DATA_PATH + '/X.npz'\n",
    "y_path = DATA_PATH + '/y.npz'\n",
    "x_s = np.load(x_path)['x']\n",
    "y_s = np.load(y_path)['y']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_s, y_s, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_size, output_size=28):\n",
    "    #########################################################\n",
    "    # Model: conv2d + conv2d + maxpool + dropout + conv2d +\n",
    "    #  bidirectional gru + dense + softmax + ctc loss\n",
    "    #########################################################\n",
    "\n",
    "    ## input_size: placeholder in Keras\n",
    "    #  shape: (None, seq_size = 20, height = 50, width = 100, channels = 3)\n",
    "    # if K.image_data_format() == 'channels_first':\n",
    "    #     input_size = (self.img_c, self.frames_n, self.img_w, self.img_h)\n",
    "    # else:\n",
    "    #     input_size = (self.frames_n, self.img_w, self.img_h, self.img_c)\n",
    "\n",
    "    # self.input_data = Input(name='the_input', shape=input_size, dtype='float32')\n",
    "    input_data = Input(name='the_input', shape=input_size, dtype='float32')\n",
    "    \n",
    "    ## padding used on the height and width before convolving\n",
    "    #  shape:(None, 20, 54, 104, 3)\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding3D(padding=(0, 2, 2),input_shape = (input_size), name='padding1'))\n",
    "\n",
    "    ## 2D Convolution on each time sequence, relu activation\n",
    "    #  shape 1st conv: (None, 20, 27, 52, 32)\n",
    "    #  shape 2nd conv: (None, 20, 14, 26, 32)\n",
    "    model.add(TimeDistributed(Conv2D(filters=34, kernel_size=(3, 3), kernel_initializer='he_normal', strides=(2, 2), padding='same', activation='relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='max1')))\n",
    "\n",
    "    model.add(TimeDistributed(Conv2D(filters=64, kernel_size=(3, 3), kernel_initializer='he_normal', strides=(2, 2), padding='same', activation='relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='max2')))\n",
    "    model.add(Dropout(0))\n",
    "\n",
    "    ## 2D Convolution on each time sequence, relu activation\n",
    "    #  shape 1st conv: (None, 20, 4, 7, 4)\n",
    "    model.add(TimeDistributed(Conv2D(filters=96, kernel_size=(3, 3), kernel_initializer='he_normal', strides=(2, 2), padding='same', activation='relu')))\n",
    "\n",
    "    ## Flatten to gru\n",
    "    #  shape: (None, 20, 112)\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(Dropout(0.0))\n",
    "    ## Bidirectional gru\n",
    "    #  shape: (None, 20, 512)\n",
    "    # x_lstm = LSTM(256, return_sequences=True, kernel_initializer='Orthogonal', name='lstm1')(input_lstm)\n",
    "    # x_lstm = LSTM(256, return_sequences=True, kernel_initializer='Orthogonal', name='lstm2')(x_lstm)\n",
    "    model.add(Bidirectional(GRU(256, return_sequences=True, kernel_initializer='Orthogonal', name='gru1'),\n",
    "                           merge_mode='concat'))\n",
    "    model.add(Bidirectional(GRU(256, return_sequences=True, kernel_initializer='Orthogonal', name='gru2'),\n",
    "                           merge_mode='concat'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_normal', name='fc1', kernel_regularizer=regularizers.l2(0.0)))\n",
    "    model.add(Dense(output_size, kernel_initializer='he_normal', name='dense2'))\n",
    "\n",
    "    ## prepare input for ctc loss\n",
    "    model.add(Activation('softmax', name='softmax'))\n",
    "    #loss = CTC('ctc', [y_pred, labels, input_length, label_length])\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "def build_model_vgg16(input_size, output_size=28):\n",
    "    input_data = Input(name='the_input', shape=input_size, dtype='float32')\n",
    "\n",
    "    vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=input_size[1:], pooling='max')\n",
    "    x = TimeDistributed(vgg16)(input_data)\n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "\n",
    "    # let's add a fully-connected layer\n",
    "    x = Bidirectional(GRU(256, return_sequences=True, name='gru1'), merge_mode='concat')(x)\n",
    "    x = Bidirectional(GRU(256, return_sequences=True, name='gru1'), merge_mode='concat')(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(4096, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    predictions = Dense(output_size, activation='softmax')(x)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=input_data, outputs=predictions)\n",
    "\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in vgg16.layers:\n",
    "       layer.trainable = False\n",
    "    model.summary()\n",
    "    return model\n",
    "def train(model, x_train, y_train, batch_size=256, epochs=100, val_train_ratio=0.2, start_epoch=0):\n",
    "    ##\n",
    "    # Train model, typically will train for each speaker\n",
    "    ## padding the labels\n",
    "    # max_string_len = 10\n",
    "    # if y_train.shape[1] != max_string_len:\n",
    "    #     y_train = pad_labels(y_train, max_string_len)\n",
    "\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "    if start_epoch > 0:\n",
    "        weight_file = os.path.join(CURRENT_PATH, \"models/model_lstm_oh.h5\")\n",
    "        model.load_weights(weight_file)\n",
    "    ## callbacks when each epoch ends\n",
    "    #  This will ouput character error rate which\n",
    "    #  compares each predicted word with source word.\n",
    "    #  TODO: results file need to be implemented\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_split=val_train_ratio,\n",
    "                        shuffle=True,\n",
    "                        initial_epoch=start_epoch,\n",
    "                        verbose=1)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "# if already has a model do not train it, this is just for test\n",
    "# model = build_model_vgg16(x_test.shape[1:], output_size=y_test.shape[1])\n",
    "# history = train(model, x_train, y_train, batch_size=256, epochs=20,\n",
    "#                     start_epoch=0)\n",
    "# model.save('model_lstm_oh.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       (None, 21, 50, 100, 3)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 21, 512)           14714688  \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 21, 512)           1181184   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 21, 512)           1181184   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10752)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              44044288  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 51)                208947    \n",
      "=================================================================\n",
      "Total params: 61,330,291.0\n",
      "Trainable params: 61,330,291.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# change model dir here\n",
    "model_dir = 'model_vgg16-gru-fc4096-lr0.0001.h5'\n",
    "model = build_model_vgg16(x_test.shape[1:], output_size=y_test.shape[1])\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "weight_file = os.path.join(CURRENT_PATH, model_dir)\n",
    "model.load_weights(weight_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('true label is: ', 3, 'predict label is :', 3)\n",
      "('true label is: ', 3, 'least label is :', 27)\n",
      "('probabilities: ', array([[  6.14955352e-05,   7.16151681e-06,   7.50396357e-05,\n",
      "          9.56085503e-01,   2.63631321e-03,   2.04445896e-04,\n",
      "          2.23993342e-02,   5.14794410e-05,   5.79983927e-04,\n",
      "          3.21533502e-04,   3.15910159e-03,   4.54713663e-05,\n",
      "          4.02157457e-06,   1.28817959e-07,   5.72489853e-06,\n",
      "          1.94282678e-04,   2.24892956e-05,   2.37194399e-06,\n",
      "          7.43483906e-05,   1.54822101e-06,   1.94282111e-04,\n",
      "          4.06555091e-06,   6.66772803e-06,   7.48415550e-06,\n",
      "          6.60496808e-05,   1.29408249e-07,   6.08751507e-05,\n",
      "          1.22314034e-07,   2.34490471e-06,   1.01880431e-02,\n",
      "          8.16547952e-04,   1.24941964e-03,   3.38988184e-06,\n",
      "          1.29785946e-07,   1.45517930e-04,   2.88151768e-05,\n",
      "          8.09063067e-07,   4.78333859e-05,   3.67561347e-06,\n",
      "          1.83302916e-06,   4.61068354e-04,   5.56491723e-05,\n",
      "          1.22480435e-06,   3.89827846e-06,   3.81612248e-04,\n",
      "          1.05904064e-05,   2.46861076e-04,   3.93560513e-05,\n",
      "          7.86730743e-06,   3.08474664e-05,   1.14355009e-06]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "# choose one sample to test\n",
    "ind = 4\n",
    "preds = model.predict(np.expand_dims(x_test[ind],0))\n",
    "pred_label = np.argmax(preds)\n",
    "least_label = np.argmin(preds)\n",
    "true_label = np.argmax(y_test[ind])\n",
    "print(\"true label is: \",true_label, \"predict label is :\", pred_label )\n",
    "print(\"true label is: \",true_label, \"least label is :\", least_label )\n",
    "print(\"probabilities: \",preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('true label is: ', None, 'predict label is :', 4)\n",
      "('true label is: ', None, 'least label is :', 9)\n",
      "('probabilities: ', array([[  2.00639246e-04,   3.77109903e-03,   1.10510550e-03,\n",
      "          2.19969079e-03,   4.05168533e-01,   2.57756021e-02,\n",
      "          1.08790089e-04,   5.47663367e-04,   9.76997311e-04,\n",
      "          9.78086609e-05,   5.66967530e-04,   2.24525778e-04,\n",
      "          2.19173473e-03,   1.09841265e-01,   4.64367418e-04,\n",
      "          2.24779658e-02,   2.96632352e-04,   6.42060826e-04,\n",
      "          5.98546118e-04,   3.80103855e-04,   4.64846846e-04,\n",
      "          8.08832177e-04,   5.78096658e-02,   7.96143548e-04,\n",
      "          1.78918970e-04,   3.57979443e-04,   5.80873247e-03,\n",
      "          1.45526283e-04,   9.15632397e-03,   1.86662108e-03,\n",
      "          2.10869163e-02,   2.61320807e-02,   3.13818455e-03,\n",
      "          5.20374393e-04,   3.71339060e-02,   3.27321119e-04,\n",
      "          1.13273323e-01,   7.69588351e-03,   8.82721797e-04,\n",
      "          4.33972627e-02,   4.45768441e-04,   5.73119968e-02,\n",
      "          1.92040857e-03,   1.68634125e-03,   3.97551665e-03,\n",
      "          8.34371662e-04,   9.01687052e-03,   6.39459235e-04,\n",
      "          1.77737197e-03,   3.49956099e-03,   1.02746105e-02]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "# check score for baseline\n",
    "from scipy.ndimage import imread\n",
    "sil_img = imread('preprocessing/sil_img.png')\n",
    "sil_img = np.zeros_like(())\n",
    "sil_img = np.stack([sil_img for _ in range(x_test[ind].shape[0])], axis =0)\n",
    "preds = model.predict(np.expand_dims(sil_img,0))\n",
    "pred_label = np.argmax(preds)\n",
    "least_label = np.argmin(preds)\n",
    "print(\"true label is: \",None, \"predict label is :\", pred_label )\n",
    "print(\"true label is: \",None, \"least label is :\", least_label )\n",
    "print(\"probabilities: \",preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from matplotlib import pylab as plt\n",
    "def show_image(image, grayscale = True, ax=None, title=''):\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "    plt.axis('off')\n",
    "    \n",
    "    if len(image.shape) == 2 or grayscale == True:\n",
    "        if len(image.shape) == 3:\n",
    "            image = np.sum(image, axis=2)\n",
    "            \n",
    "        vmax = np.percentile(image, 99)\n",
    "        vmin = np.min(image)\n",
    "\n",
    "        plt.imshow(image, cmap=plt.cm.gray, vmin=vmin, vmax=vmax)\n",
    "        plt.title(title)\n",
    "    else:\n",
    "        image = image + 127.5\n",
    "        image = image.astype('uint8')\n",
    "        \n",
    "        plt.imshow(image)\n",
    "        plt.title(title)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization - Saliency Map\n",
    "from vis.saliency import GradientSaliency\n",
    "vanilla = GradientSaliency(model,true_label)\n",
    "least_vanilla = GradientSaliency(model,least_label)\n",
    "mask_saliency = vanilla.get_mask(x_test[ind])\n",
    "least_mask_saliency = least_vanilla.get_mask(x_test[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_2/Softmax:0\n",
      "dense_2/Softmax:0\n"
     ]
    }
   ],
   "source": [
    "# visualization - guided backpropagation\n",
    "from vis.guided_backprop import GuidedBackprop\n",
    "guided_bprop = GuidedBackprop(model,true_label)\n",
    "least_guided_bprop = GuidedBackprop(model,least_label)\n",
    "mask = guided_bprop.get_mask(x_test[ind])\n",
    "least_mask = least_guided_bprop.get_mask(x_test[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vis.integrated_gradients import IntegratedGradients\n",
    "inter_grad = IntegratedGradients(model,true_label)\n",
    "least_inter_grad = IntegratedGradients(model,least_label)\n",
    "mask_integrated = inter_grad.GetMask(x_test[ind], input_baseline = sil_img, nsamples=200)\n",
    "least_mask_integrated = least_inter_grad.GetMask(x_test[ind], input_baseline = sil_img, nsamples=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "for i in range(7):\n",
    "    show_image(mask[i], ax=plt.subplot(6,7,1+i), title='GuidedBackprop')\n",
    "    show_image(least_mask[i], ax=plt.subplot(6,7,8+i), title='GuidedBackprop')\n",
    "for i in range(7):\n",
    "    show_image(mask_saliency[i], ax=plt.subplot(6,7,15+i), title='GradientSaliency')\n",
    "    show_image(least_mask_saliency[i], ax=plt.subplot(6,7,22+i), title='GradientSaliency')\n",
    "for i in range(7):\n",
    "    show_image(mask_integrated[i], ax=plt.subplot(6,7,29+i), title='IntegratedGradients')\n",
    "    show_image(least_mask_integrated[i], ax=plt.subplot(6,7,36+i), title='IntegratedGradients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
