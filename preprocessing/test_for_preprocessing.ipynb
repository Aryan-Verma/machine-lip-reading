{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align.py\n",
    "import numpy as np\n",
    "def read_align(path_to_align = None):\n",
    "    with open(path_to_align, 'r') as f:\n",
    "        lines = f.readlines()\t\n",
    "    align = [(int(y[0])/1000, int(y[1])/1000, y[2]) for y in [x.strip().split(\" \") for x in lines]]\n",
    "    words = []\n",
    "    words.append('sil')\n",
    "    for i in range(75):\n",
    "    \tfor j in align:\n",
    "\t    \tif i > j[0] and i <= j[1]:\n",
    "\t    \t\twords.append(j[2])\n",
    "    dict_align  = np.array(words)\n",
    "    return dict_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video.py\n",
    "import dlib\n",
    "from skvideo.io import vread\n",
    "from scipy.misc import imresize\n",
    "def read_video(path, face_predictor_path, verbose=False):\n",
    "    if verbose:\n",
    "        print(\"loading: \" + path)\n",
    "    video = vread(path)\n",
    "    frames = np.array([frame for frame in video])\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(face_predictor_path)\n",
    "    mouth_video = get_frames_mouth(detector, predictor, frames)\n",
    "\n",
    "    return np.array(mouth_video)\n",
    "\n",
    "def get_frames_mouth(detector, predictor, frames):\n",
    "        MOUTH_WIDTH = 100\n",
    "        MOUTH_HEIGHT = 50\n",
    "        HORIZONTAL_PAD = 0.19\n",
    "        normalize_ratio = None\n",
    "        mouth_frames = []\n",
    "        for frame in frames:\n",
    "            dets = detector(frame, 1)\n",
    "            shape = None\n",
    "            for k, d in enumerate(dets):\n",
    "                shape = predictor(frame, d)\n",
    "                i = -1\n",
    "            if shape is None: # Detector doesn't detect face, just return as is\n",
    "                return frames\n",
    "            mouth_points = []\n",
    "            for part in shape.parts():\n",
    "                i += 1\n",
    "                if i < 48: # Only take mouth region\n",
    "                    continue\n",
    "                mouth_points.append((part.x,part.y))\n",
    "            np_mouth_points = np.array(mouth_points)\n",
    "\n",
    "            mouth_centroid = np.mean(np_mouth_points[:, -2:], axis=0)\n",
    "\n",
    "            if normalize_ratio is None:\n",
    "                mouth_left = np.min(np_mouth_points[:, :-1]) * (1.0 - HORIZONTAL_PAD)\n",
    "                mouth_right = np.max(np_mouth_points[:, :-1]) * (1.0 + HORIZONTAL_PAD)\n",
    "\n",
    "                normalize_ratio = MOUTH_WIDTH / float(mouth_right - mouth_left)\n",
    "\n",
    "            new_img_shape = (int(frame.shape[0] * normalize_ratio), int(frame.shape[1] * normalize_ratio))\n",
    "            resized_img = imresize(frame, new_img_shape)\n",
    "\n",
    "            mouth_centroid_norm = mouth_centroid * normalize_ratio\n",
    "\n",
    "            mouth_l = int(mouth_centroid_norm[0] - MOUTH_WIDTH / 2)\n",
    "            mouth_r = int(mouth_centroid_norm[0] + MOUTH_WIDTH / 2)\n",
    "            mouth_t = int(mouth_centroid_norm[1] - MOUTH_HEIGHT / 2)\n",
    "            mouth_b = int(mouth_centroid_norm[1] + MOUTH_HEIGHT / 2)\n",
    "\n",
    "            mouth_crop_image = resized_img[mouth_t:mouth_b, mouth_l:mouth_r]\n",
    "\n",
    "            mouth_frames.append(mouth_crop_image)\n",
    "        return mouth_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.py\n",
    "import os\n",
    "#from align import read_align\n",
    "#from video import read_video\n",
    "\n",
    "# different from file\n",
    "CURRENT_PATH = '/home/ubuntu/Project/machine-lip-reading/preprocessing'\n",
    "DATA_PATH = CURRENT_PATH + '/../data'\n",
    "PREDICTOR_PATH = CURRENT_PATH + '/shape_predictor_68_face_landmarks.dat'\n",
    "\n",
    "def load_data(verbose=False, framebyframe=False):\n",
    "    for root, dirs, files in os.walk(DATA_PATH):\n",
    "        for name in files:\n",
    "            if '.mpg' in name:\n",
    "                if verbose is True:\n",
    "                    print(\"reading: \" + root)\n",
    "                video = read_video(os.path.join(root, name), PREDICTOR_PATH)\n",
    "                words = read_align(os.path.join(root, '../align/', name.split(\".\")[0] + \".align\"))\n",
    "               \n",
    "                if verbose is True:\n",
    "                    print(\"video shape:\", video.shape)\n",
    "                    print(\"alignments shape:\", words.shape)\n",
    "\n",
    "                if framebyframe:\n",
    "                    for frame, word in zip(video, words):\n",
    "                        yield frame, word\n",
    "                else:\n",
    "                    yield video, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/ipykernel_launcher.py:47: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    }
   ],
   "source": [
    "# show some preprocessing results\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imsave\n",
    "# for img, word in load_data(verbose=False, framebyframe=False):\n",
    "#     for i in range(75):\n",
    "#         print i\n",
    "#         if i == 0:\n",
    "#             print word[i]\n",
    "#         elif word[i] != word[i-1]:\n",
    "#             print word[i]\n",
    "#         plt.imshow(img[i,:,:,:])\n",
    "        \n",
    "#         plt.show()\n",
    "#     break  \n",
    "CURRENT_PATH = '/home/ubuntu/project/machine-lip-reading/preprocessing'\n",
    "PREDICTOR_PATH = CURRENT_PATH + '/shape_predictor_68_face_landmarks.dat'\n",
    "img = read_video(os.path.join(CURRENT_PATH, '../data/bbaf2n.mpg'), PREDICTOR_PATH)\n",
    "\n",
    "imsave('sil_img.png',img[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
