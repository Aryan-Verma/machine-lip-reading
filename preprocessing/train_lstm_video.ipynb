{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from data import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers.wrappers import TimeDistributed, Bidirectional\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding3D\n",
    "from keras.layers.core import Lambda, Dropout, Flatten, Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = '/home/ubuntu/assignments/machine-lip-reading/preprocessing'\n",
    "DATA_PATH = CURRENT_PATH + '/../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    import tensorflow as tf\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # From Keras example image_ocr.py:\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    # y_pred = y_pred[:, 2:, :]\n",
    "    label_length = K.cast(tf.squeeze(label_length),'int32')\n",
    "    input_length = K.cast(tf.squeeze(input_length),'int32')\n",
    "    labels = K.ctc_label_dense_to_sparse(labels, label_length)\n",
    "    #y_pred = y_pred[:, :, :]\n",
    "    #return K.ctc_batch_cost(labels, y_pred, input_length, label_length, ignore_longer_outputs_than_inputs=True)\n",
    "    return tf.nn.ctc_loss(labels, y_pred, input_length, ctc_merge_repeated=False,\n",
    "                         ignore_longer_outputs_than_inputs = True, time_major = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTC(name, args):\n",
    "\treturn Lambda(ctc_lambda_func, output_shape=(1,), name=name)(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_size, output_size = 28, max_string_len = 10):\n",
    "    # model = Sequential()\n",
    "    input_data = Input(name='the_input', shape=input_size, dtype='float32')\n",
    "    x = ZeroPadding3D(padding=(0,2,2), name='padding1')(input_data)\n",
    "    x = TimeDistributed(Conv2D(filters = 32, kernel_size = 5, strides = (2,2),\n",
    "                             padding = 'same', activation = 'relu'))(x)\n",
    "    print\n",
    "    x = TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=None, name='max1'))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = TimeDistributed(Conv2D(filters=32, kernel_size=5, strides=(2, 2),\n",
    "                               padding='same', activation='relu'))(x)\n",
    "    x = TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=None, name='max1'))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = TimeDistributed(Conv2D(filters=4, kernel_size=5, strides=(2, 2),\n",
    "                               padding='same', activation='relu'))(x)\n",
    "    x = TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=None, name='max1'))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    input_lstm = TimeDistributed(Flatten())(x)\n",
    "\n",
    "    x_lstm = Bidirectional(GRU(256, return_sequences=True, kernel_initializer='Orthogonal', name='gru1'), merge_mode='concat')(input_lstm)\n",
    "    x_lstm = Dense(output_size, kernel_initializer='he_normal', name='dense1')(x_lstm)\n",
    "    print(\"after dense1\")\n",
    "    y_pred = Activation('softmax', name='softmax')(x_lstm)\n",
    "\n",
    "    labels = Input(name='the_labels', shape = [max_string_len], dtype='int32')\n",
    "    input_length = Input(name = 'input_length', shape =[1], dtype = 'int32')\n",
    "    label_length = Input(name = 'label_length', shape = [1], dtype = 'int32')\n",
    "    loss = CTC('ctc',[y_pred, labels, input_length, label_length])\n",
    "    model = Model(inputs=[input_data, labels, label_length, input_length],\n",
    "                  outputs = loss)\n",
    "    model.summary()\n",
    "    # Build model here...\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_labels(labels, max_string_len):\n",
    "    padding = np.ones((labels.shape[0], max_string_len - labels.shape[1])) * -1\n",
    "    return np.concatenate((labels, padding), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x_train, y_train, label_len_train, input_len_train, batch_size=256, epochs=100, val_train_ratio=0.2):\n",
    "    max_string_len = 10\n",
    "    if y_train.shape[1] != max_string_len:\n",
    "        y_train = pad_labels(y_train, max_string_len)\n",
    "\n",
    "    adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=adam)\n",
    "    history = model.fit(x = {'the_input':x_train, 'the_labels':y_train, 'label_length':label_len_train,\n",
    "                             'input_length':input_len_train}, y = {'ctc': np.zeros([x_train.shape[0]])},\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_split=val_train_ratio,\n",
    "                        shuffle=True,\n",
    "                        verbose=1)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    oh = OneHotEncoder()\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    x = list()\n",
    "    y = list()\n",
    "    t = list()\n",
    "    print(\"loading images...\")\n",
    "    for i, (img, words) in enumerate(load_data(DATA_PATH, verbose=False, framebyframe=False)):\n",
    "        if img.shape[0] != 75:\n",
    "            continue\n",
    "        x.append(img)\n",
    "        y.append(words)\n",
    "\n",
    "        t += words.tolist()\n",
    "        if i == 3:\n",
    "            break\n",
    "\n",
    "    t = le.fit_transform(t)\n",
    "    oh.fit(t.reshape(-1, 1))\n",
    "\n",
    "    print(\"convering to np array...\")\n",
    "    x = np.stack(x, axis=0)\n",
    "\n",
    "    print(\"transforming y...\")\n",
    "    for i in range(len(y)):\n",
    "        y_ = le.transform(y[i])\n",
    "        y[i] = np.asarray(oh.transform(y_.reshape(-1, 1)).todense())\n",
    "    y = np.stack(y, axis=0)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from align import read_align\n",
    "from video import read_video\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import re\n",
    "\n",
    "CURRENT_PATH = '/home/ubuntu/assignments/machine-lip-reading/preprocessing'\n",
    "DATA_PATH = CURRENT_PATH + '/../data'\n",
    "PREDICTOR_PATH = CURRENT_PATH + '/shape_predictor_68_face_landmarks.dat'\n",
    "SAVE_NUMPY_PATH = CURRENT_PATH + '/../data/numpy_results'\n",
    "\n",
    "\n",
    "def text_to_labels(text):\n",
    "    ret = []\n",
    "    for char in text:\n",
    "        if char >= 'a' and char <= 'z':\n",
    "            ret.append(ord(char) - ord('a'))\n",
    "        elif char == ' ':\n",
    "            ret.append(26)\n",
    "    return ret\n",
    "\n",
    "def labels_to_text(labels):\n",
    "# 26 is space, 27 is CTC blank char\n",
    "    text = ''\n",
    "    for c in labels:\n",
    "        if c >= 0 and c < 26:\n",
    "            text += chr(c + ord('a'))\n",
    "        elif c == 26:\n",
    "            text += ' '\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from align import read_align\n",
    "from video import read_video\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "CURRENT_PATH = '/home/ubuntu/assignments/machine-lip-reading/preprocessing'\n",
    "# CURRENT_PATH = os.path.dirname(os.path.abspath(__file__))\n",
    "DATA_PATH = CURRENT_PATH + '/../data'\n",
    "PREDICTOR_PATH = CURRENT_PATH + '/shape_predictor_68_face_landmarks.dat'\n",
    "\n",
    "\n",
    "def text_to_labels(text):\n",
    "    ret = []\n",
    "    for char in text:\n",
    "        if char >= 'a' and char <= 'z':\n",
    "            ret.append(ord(char) - ord('a'))\n",
    "        elif char == ' ':\n",
    "            ret.append(26)\n",
    "    return ret\n",
    "\n",
    "def labels_to_text(labels):\n",
    "# 26 is space, 27 is CTC blank char\n",
    "    text = ''\n",
    "    for c in labels:\n",
    "        if c >= 0 and c < 26:\n",
    "            text += chr(c + ord('a'))\n",
    "        elif c == 26:\n",
    "            text += ' '\n",
    "    return text\n",
    "\n",
    "def load_data(datapath, speaker, verbose=True, num_samples=1000, ctc_encoding=True):\n",
    "    oh = OneHotEncoder()\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    counter = 0\n",
    "    done = False\n",
    "\n",
    "    max_len = 0\n",
    "    max_word_len = 0\n",
    "\n",
    "    x = list()\n",
    "    y = list()\n",
    "    \n",
    "    word_len_list = []\n",
    "    input_len_list = []\n",
    "    \n",
    "    path = datapath + '/' + str(speaker)\n",
    "    for root, dirs, files in os.walk(datapath):\n",
    "        for name in files:\n",
    "            if '.mpg' in name:\n",
    "                if verbose is True:\n",
    "                    print(str(counter) + \": reading - \" + root + name)\n",
    "\n",
    "                video = read_video(os.path.join(root, name), PREDICTOR_PATH)\n",
    "                alignments = read_align(os.path.join(root, '../align/', name.split(\".\")[0] + \".align\"))\n",
    "\n",
    "                for start, stop, word in alignments:\n",
    "                    if word == 'sil' or word == 'sp':\n",
    "                        continue\n",
    "                   \n",
    "                    if (len(x) > 0):\n",
    "                        _, d1, d2, d3 = video[start:stop].shape\n",
    "                        _, prev_d1, prev_d2, prev_d3 = x[-1].shape\n",
    "                        if (d1, d2, d3) != (prev_d1, prev_d2, prev_d3):\n",
    "                            if verbose is True:\n",
    "                                print(\"different size, skip\")\n",
    "                            continue\n",
    "                    \n",
    "                    x.append(video[start:stop])\n",
    "                    y.append(word)\n",
    "                            \n",
    "                    max_word_len = max(max_word_len, len(word))\n",
    "                    max_len = max(max_len, stop-start)\n",
    "\n",
    "                    word_len_list.append(len(word))\n",
    "                    input_len_list.append(stop-start)\n",
    "                    \n",
    "                    counter += 1\n",
    "                    if counter % num_samples == 0:\n",
    "                        \n",
    "                        if not ctc_encoding:\n",
    "                            y = le.fit_transform(y)\n",
    "                            y = oh.fit_transform(y.reshape(-1, 1)).todense()\n",
    "\n",
    "                        for i in range(len(x)):\n",
    "                            result = np.zeros((max_len, 50, 100, 3))\n",
    "                            result[:x[i].shape[0], :x[i].shape[1], :x[i].shape[2], :x[i].shape[3]] = x[i]\n",
    "                            x[i] = result\n",
    "\n",
    "                            if ctc_encoding:\n",
    "                                res = np.ones(max_word_len) * -1\n",
    "                                enc = np.array(text_to_labels(y[i]))\n",
    "                                res[:enc.shape[0]] = enc\n",
    "                                y[i] = res\n",
    "\n",
    "                        if ctc_encoding:\n",
    "                            y = np.stack(y, axis=0)\n",
    "\n",
    "                        x = np.stack(x, axis=0)\n",
    "\n",
    "                        print('saving numpy')\n",
    "                        np.savez_compressed(str(speaker) + '_x_' + str(counter % num_samples), x=x)\n",
    "                        np.savez_compressed(str(speaker) + '_y_' + str(counter % num_samples), y=y)\n",
    "                        np.savez_compressed(str(speaker) + '_wi_' + str(counter % num_samples),\n",
    "                                            word_length=word_len_list, input_length=input_len_list)\n",
    "                        \n",
    "\n",
    "                        max_len = 0\n",
    "                        max_word_len = 0\n",
    "\n",
    "                        x = list()\n",
    "                        y = list()\n",
    "\n",
    "                        word_len_list = []\n",
    "                        input_len_list = []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopwaj8p.mpg\n",
      "6: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobbifzp.mpg\n",
      "12: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobras7s.mpg\n",
      "18: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosbwh8p.mpg\n",
      "24: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolwwm1s.mpg\n",
      "30: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobgbb2p.mpg\n",
      "36: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolrik4p.mpg\n",
      "42: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolgamzp.mpg\n",
      "48: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopwwq8n.mpg\n",
      "54: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolrar3a.mpg\n",
      "60: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videoprwx9a.mpg\n",
      "66: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopgbe4p.mpg\n",
      "72: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolrwl6p.mpg\n",
      "78: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopbwp6n.mpg\n",
      "84: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videoswao7a.mpg\n",
      "90: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolwar8p.mpg\n",
      "96: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videoswwjzp.mpg\n",
      "102: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobrim1a.mpg\n",
      "108: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopwax6p.mpg\n",
      "114: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosbba9s.mpg\n",
      "120: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobbizzn.mpg\n",
      "different size, skip\n",
      "different size, skip\n",
      "different size, skip\n",
      "different size, skip\n",
      "different size, skip\n",
      "different size, skip\n",
      "120: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolbby3s.mpg\n",
      "126: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolrwf2p.mpg\n",
      "132: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosgio9a.mpg\n",
      "138: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobriz7s.mpg\n",
      "144: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobbwtzp.mpg\n",
      "150: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosgbv9s.mpg\n",
      "156: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobgig8p.mpg\n",
      "162: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobriz6n.mpg\n",
      "168: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobwwn7s.mpg\n",
      "174: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobwwn9a.mpg\n",
      "180: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosgio6n.mpg\n",
      "186: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videoprbx3s.mpg\n",
      "192: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videoswao4n.mpg\n",
      "198: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosrbh9s.mpg\n",
      "204: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobris5a.mpg\n",
      "210: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolbbq8n.mpg\n",
      "216: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobbal8p.mpg\n",
      "222: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolbwy6n.mpg\n",
      "228: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolrbzzp.mpg\n",
      "234: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopgbr3a.mpg\n",
      "240: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolwwf7s.mpg\n",
      "246: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopwaq1s.mpg\n",
      "252: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopbbj1a.mpg\n",
      "258: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosrwv2p.mpg\n",
      "264: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosrwi2n.mpg\n",
      "270: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobbwg3a.mpg\n",
      "276: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobgwh8n.mpg\n",
      "282: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobrbt1s.mpg\n",
      "288: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videoprwx8p.mpg\n",
      "294: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolgaz6n.mpg\n",
      "300: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videoswiu7a.mpg\n",
      "306: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosgwp8n.mpg\n",
      "312: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobwwh3s.mpg\n",
      "318: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosgbc8p.mpg\n",
      "324: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobwaa2p.mpg\n",
      "330: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopgby6p.mpg\n",
      "336: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolrik3s.mpg\n",
      "342: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopbbp4p.mpg\n",
      "348: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videoprwk1a.mpg\n",
      "354: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolbij9a.mpg\n",
      "360: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopgik1a.mpg\n",
      "366: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolgwm6n.mpg\n",
      "372: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopgby5s.mpg\n",
      "378: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobwis8n.mpg\n",
      "384: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolbiq3a.mpg\n",
      "390: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolbwl1a.mpg\n",
      "396: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosrwo9a.mpg\n",
      "402: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolwwm3a.mpg\n",
      "408: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosrwo6n.mpg\n",
      "414: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolwazzn.mpg\n",
      "420: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosgio8p.mpg\n",
      "426: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosbbu1s.mpg\n",
      "432: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobgbo1a.mpg\n",
      "438: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolbak2p.mpg\n",
      "444: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopgwy9s.mpg\n",
      "450: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolrby8n.mpg\n",
      "456: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobbbf9a.mpg\n",
      "462: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolrbe7s.mpg\n",
      "468: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolwaz1s.mpg\n",
      "474: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobwim5s.mpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopwad2n.mpg\n",
      "486: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videoswavzp.mpg\n",
      "492: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobgbu3s.mpg\n",
      "498: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosbig6p.mpg\n",
      "504: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolgbm2n.mpg\n",
      "510: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosbaa4n.mpg\n",
      "516: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobbwm7a.mpg\n",
      "522: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopgwr7a.mpg\n",
      "528: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobbas2p.mpg\n",
      "534: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosgac4p.mpg\n",
      "540: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopbii2p.mpg\n",
      "546: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videoswau8n.mpg\n",
      "552: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolbix5s.mpg\n",
      "558: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopbiizn.mpg\n",
      "564: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosgac2n.mpg\n",
      "570: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolrik5a.mpg\n",
      "576: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosbwo3a.mpg\n",
      "582: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosbwu6p.mpg\n",
      "588: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosrih1s.mpg\n",
      "594: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolbwe5s.mpg\n",
      "600: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolbwy7s.mpg\n",
      "606: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolwwf6n.mpg\n",
      "612: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosrab3a.mpg\n",
      "618: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolwbf2n.mpg\n",
      "624: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopwbq7a.mpg\n",
      "630: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolwal4p.mpg\n",
      "636: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolbax9s.mpg\n",
      "642: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopgayzn.mpg\n",
      "648: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolbbe3a.mpg\n",
      "654: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobgwb7a.mpg\n",
      "660: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopbai5s.mpg\n",
      "666: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videoprbj7a.mpg\n",
      "672: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopbii3a.mpg\n",
      "678: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolgbm3s.mpg\n",
      "684: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videoprwd6p.mpg\n",
      "690: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videoprwj8n.mpg\n",
      "696: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolbbezn.mpg\n",
      "702: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopgwlzn.mpg\n",
      "708: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videoswbv5a.mpg\n",
      "714: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolwbs2p.mpg\n",
      "720: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobbwgzn.mpg\n",
      "726: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobrwg6n.mpg\n",
      "732: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobrwa5a.mpg\n",
      "738: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videoswio3a.mpg\n",
      "744: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobris3s.mpg\n",
      "750: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosrihzn.mpg\n",
      "756: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopgak2n.mpg\n",
      "762: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolgir9s.mpg\n",
      "768: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videoswbc3a.mpg\n",
      "774: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videoprwkzp.mpg\n",
      "780: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopwwy5a.mpg\n",
      "786: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosgai6n.mpg\n",
      "792: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobrif7a.mpg\n",
      "798: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobbaf5a.mpg\n",
      "804: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopwwq9s.mpg\n",
      "810: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosrwv3a.mpg\n",
      "816: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobrif5s.mpg\n",
      "822: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopbai6p.mpg\n",
      "828: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosrabzn.mpg\n",
      "834: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosgic1a.mpg\n",
      "840: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolbakzn.mpg\n",
      "846: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobgbh5s.mpg\n",
      "852: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopgaezp.mpg\n",
      "858: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolrwz3s.mpg\n",
      "864: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolbbe1s.mpg\n",
      "870: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolrbe9a.mpg\n",
      "876: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopbbp5a.mpg\n",
      "882: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosrah4n.mpg\n",
      "888: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolrwl5s.mpg\n",
      "894: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopbivzp.mpg\n",
      "900: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosgivzn.mpg\n",
      "906: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobgbbzn.mpg\n",
      "912: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolwie6p.mpg\n",
      "918: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopgwe8p.mpg\n",
      "924: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopgid4n.mpg\n",
      "930: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolbax8n.mpg\n",
      "936: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolwie4n.mpg\n",
      "942: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosrah6p.mpg\n",
      "948: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosbig4n.mpg\n",
      "954: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosrah7a.mpg\n",
      "960: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videosrbb6p.mpg\n",
      "966: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopriv7a.mpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "972: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopwij2n.mpg\n",
      "978: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobragzp.mpg\n",
      "984: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videolbwe6p.mpg\n",
      "990: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videobbws9s.mpg\n",
      "996: reading - /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/videopgid7a.mpg\n",
      "saving numpy\n"
     ]
    }
   ],
   "source": [
    "load_data(DATA_PATH, 's1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
