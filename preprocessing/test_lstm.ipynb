{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "reading: /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/video/bbifzp.mpg\n",
      "0: 16--21: bin\n",
      "1: 21--26: blue\n",
      "2: 26--28: in\n",
      "3: 28--32: f\n",
      "4: 32--40: zero\n",
      "5: 40--51: please\n",
      "reading: /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/video/bbizzn.mpg\n",
      "6: 16--22: bin\n",
      "different size, skip\n",
      "6: 22--27: blue\n",
      "different size, skip\n",
      "6: 27--31: in\n",
      "different size, skip\n",
      "6: 31--36: z\n",
      "different size, skip\n",
      "6: 36--45: zero\n",
      "different size, skip\n",
      "6: 45--51: now\n",
      "different size, skip\n",
      "reading: /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/video/bbal8p.mpg\n",
      "6: 22--27: bin\n",
      "7: 27--31: blue\n",
      "8: 31--32: at\n",
      "9: 32--36: l\n",
      "10: 36--40: eight\n",
      "11: 40--50: please\n",
      "reading: /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/video/bbbf9a.mpg\n",
      "12: 22--27: bin\n",
      "13: 27--31: blue\n",
      "14: 31--35: by\n",
      "15: 35--39: f\n",
      "16: 39--45: nine\n",
      "17: 45--54: again\n",
      "reading: /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/video/bbas2p.mpg\n",
      "18: 15--21: bin\n",
      "19: 21--25: blue\n",
      "20: 25--27: at\n",
      "21: 27--32: s\n",
      "22: 32--37: two\n",
      "23: 37--47: please\n",
      "reading: /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/video/bbaf5a.mpg\n",
      "24: 17--23: bin\n",
      "25: 23--30: blue\n",
      "26: 30--35: at\n",
      "27: 35--42: f\n",
      "28: 42--49: five\n",
      "29: 49--57: again\n",
      "reading: /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/video/bbir6n.mpg\n",
      "30: 18--24: bin\n",
      "31: 24--30: blue\n",
      "32: 30--32: in\n",
      "33: 32--36: r\n",
      "34: 36--44: six\n",
      "35: 44--51: now\n",
      "reading: /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/video/bbil5a.mpg\n",
      "36: 16--22: bin\n",
      "37: 22--27: blue\n",
      "38: 27--28: in\n",
      "39: 28--32: l\n",
      "40: 32--39: five\n",
      "41: 39--47: again\n",
      "reading: /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/video/bbaf3s.mpg\n",
      "42: 17--22: bin\n",
      "43: 22--27: blue\n",
      "44: 27--28: at\n",
      "45: 28--31: f\n",
      "46: 31--36: three\n",
      "47: 36--46: soon\n",
      "reading: /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/video/bbiz3a.mpg\n",
      "48: 14--20: bin\n",
      "49: 20--25: blue\n",
      "50: 25--27: in\n",
      "51: 27--31: z\n",
      "52: 31--38: three\n",
      "53: 38--48: again\n",
      "reading: /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/video/bbbm1s.mpg\n",
      "54: 14--19: bin\n",
      "55: 19--24: blue\n",
      "56: 24--28: by\n",
      "57: 28--31: m\n",
      "58: 31--35: one\n",
      "59: 35--45: soon\n",
      "reading: /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/video/bbas1s.mpg\n",
      "60: 13--20: bin\n",
      "61: 20--25: blue\n",
      "62: 25--27: at\n",
      "63: 27--32: s\n",
      "64: 32--36: one\n",
      "65: 36--45: soon\n",
      "reading: /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/video/bbbz9s.mpg\n",
      "66: 18--23: bin\n",
      "67: 23--31: blue\n",
      "68: 31--36: by\n",
      "69: 36--41: z\n",
      "70: 41--47: nine\n",
      "71: 47--56: soon\n",
      "reading: /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/video/bbif1a.mpg\n",
      "72: 15--21: bin\n",
      "73: 21--25: blue\n",
      "74: 25--27: in\n",
      "75: 27--32: f\n",
      "76: 32--36: one\n",
      "77: 36--45: again\n",
      "reading: /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/video/bbaz5s.mpg\n",
      "78: 18--23: bin\n",
      "79: 23--30: blue\n",
      "80: 30--31: at\n",
      "81: 31--35: z\n",
      "82: 35--43: five\n",
      "83: 43--52: soon\n",
      "reading: /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/video/bbbs6p.mpg\n",
      "84: 13--19: bin\n",
      "85: 19--24: blue\n",
      "86: 24--28: by\n",
      "87: 28--33: s\n",
      "88: 33--39: six\n",
      "89: 39--48: please\n",
      "reading: /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/video/bbbs5s.mpg\n",
      "90: 21--28: bin\n",
      "91: 28--34: blue\n",
      "92: 34--38: by\n",
      "93: 38--45: s\n",
      "94: 45--52: five\n",
      "95: 52--63: soon\n",
      "reading: /home/ubuntu/assignments/machine-lip-reading/preprocessing/../data/s1/video/bbie9s.mpg\n",
      "96: 15--21: bin\n",
      "97: 21--26: blue\n",
      "98: 26--28: in\n",
      "99: 28--31: e\n",
      "0: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "1: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "2: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "3: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "4: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "5: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "6: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "7: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "8: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "9: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "10: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "11: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "12: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "13: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "14: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "15: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "16: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "17: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "18: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "19: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "20: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "21: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "22: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "23: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "24: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "25: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "26: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "27: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "28: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "29: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "30: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "31: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "32: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "33: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "34: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "35: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "36: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "37: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "38: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "39: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "40: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "41: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "42: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "43: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "44: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "45: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "46: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "47: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "48: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "49: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "50: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "51: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "52: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "53: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "54: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "55: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "56: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "57: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "58: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "59: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "60: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "61: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "62: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "63: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "64: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "65: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "66: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "67: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "68: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "69: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "70: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "71: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "72: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "73: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "74: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "75: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "76: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "77: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "78: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "79: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "80: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "81: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "82: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "83: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "84: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "85: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "86: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "87: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "88: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "89: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "90: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "91: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "92: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "93: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "94: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "95: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "96: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "97: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "98: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "99: (11, 50, 100, 3)\n",
      "Added: (11, 50, 100, 3)\n",
      "('load data took', 139.45508909225464)\n",
      "('training data shapes:', (100, 11, 50, 100, 3), (100, 6))\n",
      "\n",
      "after dense1\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 11, 50, 100,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "padding1 (ZeroPadding3D)        (None, 11, 54, 104,  0           the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 11, 27, 52, 3 2432        padding1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 11, 13, 26, 3 0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 11, 13, 26, 3 0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 11, 7, 13, 32 25632       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 11, 3, 6, 32) 0           time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 11, 3, 6, 32) 0           time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 11, 2, 3, 4)  3204        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 11, 1, 1, 4)  0           time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 11, 1, 1, 4)  0           time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 11, 4)        0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 11, 512)      400896      time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 11, 28)       14364       bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 11, 28)       0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           softmax[0][0]                    \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 446,528\n",
      "Trainable params: 446,528\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 16 samples\n",
      "Epoch 1/100\n",
      "64/64 [==============================] - 3s 45ms/step - loss: 16.6773 - val_loss: 13.4285\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 16.6615 - val_loss: 13.4174\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 16.6391 - val_loss: 13.4062\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 16.6178 - val_loss: 13.3964\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 16.6025 - val_loss: 13.3862\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 16.5769 - val_loss: 13.3758\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 16.5534 - val_loss: 13.3642\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 2s 30ms/step - loss: 16.5190 - val_loss: 13.3512\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 2s 33ms/step - loss: 16.4889 - val_loss: 13.3363\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 16.4408 - val_loss: 13.3185\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 16.4091 - val_loss: 13.2970\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 16.3535 - val_loss: 13.2717\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 16.2898 - val_loss: 13.2404\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 16.2519 - val_loss: 13.2020\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 16.1818 - val_loss: 13.1577\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 16.0965 - val_loss: 13.1037\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 16.0385 - val_loss: 13.0423\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 16.0056 - val_loss: 12.9788\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 15.8817 - val_loss: 12.9150\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 15.7973 - val_loss: 12.8541\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 15.7265 - val_loss: 12.7966\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 15.6585 - val_loss: 12.7438\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 15.5568 - val_loss: 12.6949\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 15.4799 - val_loss: 12.6450\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 15.3800 - val_loss: 12.5970\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 15.2792 - val_loss: 12.5463\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 15.2002 - val_loss: 12.4950\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 15.1095 - val_loss: 12.4441\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 15.0552 - val_loss: 12.3962\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 15.0500 - val_loss: 12.3516\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.9315 - val_loss: 12.3106\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.8942 - val_loss: 12.2738\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.8345 - val_loss: 12.2410\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.7871 - val_loss: 12.2120\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.7484 - val_loss: 12.1862\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.6991 - val_loss: 12.1640\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.7491 - val_loss: 12.1443\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.6700 - val_loss: 12.1270\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.6400 - val_loss: 12.1120\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.6620 - val_loss: 12.0987\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.5811 - val_loss: 12.0869\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.6123 - val_loss: 12.0765\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.5290 - val_loss: 12.0674\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.5183 - val_loss: 12.0595\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.5154 - val_loss: 12.0524\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.5963 - val_loss: 12.0460\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.5432 - val_loss: 12.0404\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.5543 - val_loss: 12.0355\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4980 - val_loss: 12.0311\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.5047 - val_loss: 12.0272\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4902 - val_loss: 12.0238\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.5135 - val_loss: 12.0207\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.5080 - val_loss: 12.0179\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4543 - val_loss: 12.0155\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4796 - val_loss: 12.0132\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4559 - val_loss: 12.0112\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4744 - val_loss: 12.0094\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4858 - val_loss: 12.0077\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4424 - val_loss: 12.0062\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4330 - val_loss: 12.0049\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4570 - val_loss: 12.0036\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4895 - val_loss: 12.0024\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4374 - val_loss: 12.0014\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4414 - val_loss: 12.0004\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4296 - val_loss: 11.9995\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4431 - val_loss: 11.9986\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4273 - val_loss: 11.9978\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4263 - val_loss: 11.9970\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4789 - val_loss: 11.9963\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4171 - val_loss: 11.9957\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4282 - val_loss: 11.9951\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4258 - val_loss: 11.9945\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4329 - val_loss: 11.9940\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4122 - val_loss: 11.9935\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4168 - val_loss: 11.9930\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4348 - val_loss: 11.9925\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4249 - val_loss: 11.9921\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4298 - val_loss: 11.9917\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4263 - val_loss: 11.9913\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4275 - val_loss: 11.9909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4195 - val_loss: 11.9905\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4350 - val_loss: 11.9902\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4224 - val_loss: 11.9899\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4126 - val_loss: 11.9895\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4150 - val_loss: 11.9892\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4150 - val_loss: 11.9889\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4124 - val_loss: 11.9887\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4242 - val_loss: 11.9884\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4029 - val_loss: 11.9881\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.3973 - val_loss: 11.9879\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4117 - val_loss: 11.9876\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4054 - val_loss: 11.9874\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4156 - val_loss: 11.9872\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4153 - val_loss: 11.9870\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4099 - val_loss: 11.9868\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4026 - val_loss: 11.9866\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4050 - val_loss: 11.9864\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4132 - val_loss: 11.9862\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4142 - val_loss: 11.9860\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 14.4139 - val_loss: 11.9858\n",
      "Saving model...\n",
      "Plotting...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from data import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers.wrappers import TimeDistributed, Bidirectional\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding3D\n",
    "from keras.layers.core import Lambda, Dropout, Flatten, Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "CURRENT_PATH = '/home/ubuntu/assignments/machine-lip-reading/preprocessing'\n",
    "DATA_PATH = CURRENT_PATH + '/../data'\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    import tensorflow as tf\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # From Keras example image_ocr.py:\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    # y_pred = y_pred[:, 2:, :]\n",
    "    label_length = K.cast(tf.squeeze(label_length),'int32')\n",
    "    input_length = K.cast(tf.squeeze(input_length),'int32')\n",
    "    labels = K.ctc_label_dense_to_sparse(labels, label_length)\n",
    "    #y_pred = y_pred[:, :, :]\n",
    "    #return K.ctc_batch_cost(labels, y_pred, input_length, label_length, ignore_longer_outputs_than_inputs=True)\n",
    "    return tf.nn.ctc_loss(labels, y_pred, input_length, ctc_merge_repeated=False,\n",
    "                         ignore_longer_outputs_than_inputs = True, time_major = False)\n",
    "def CTC(name, args):\n",
    "\treturn Lambda(ctc_lambda_func, output_shape=(1,), name=name)(args)\n",
    "\n",
    "\n",
    "def build_model(input_size, output_size = 28, max_string_len = 10):\n",
    "    # model = Sequential()\n",
    "    input_data = Input(name='the_input', shape=input_size, dtype='float32')\n",
    "    x = ZeroPadding3D(padding=(0,2,2), name='padding1')(input_data)\n",
    "    x = TimeDistributed(Conv2D(filters = 32, kernel_size = 5, strides = (2,2),\n",
    "                             padding = 'same', activation = 'relu'))(x)\n",
    "    print\n",
    "    x = TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=None, name='max1'))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = TimeDistributed(Conv2D(filters=32, kernel_size=5, strides=(2, 2),\n",
    "                               padding='same', activation='relu'))(x)\n",
    "    x = TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=None, name='max1'))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = TimeDistributed(Conv2D(filters=4, kernel_size=5, strides=(2, 2),\n",
    "                               padding='same', activation='relu'))(x)\n",
    "    x = TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=None, name='max1'))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    input_lstm = TimeDistributed(Flatten())(x)\n",
    "\n",
    "    x_lstm = Bidirectional(GRU(256, return_sequences=True, kernel_initializer='Orthogonal', name='gru1'), merge_mode='concat')(input_lstm)\n",
    "    x_lstm = Dense(output_size, kernel_initializer='he_normal', name='dense1')(x_lstm)\n",
    "    print(\"after dense1\")\n",
    "    y_pred = Activation('softmax', name='softmax')(x_lstm)\n",
    "\n",
    "    labels = Input(name='the_labels', shape = [max_string_len], dtype='int32')\n",
    "    input_length = Input(name = 'input_length', shape =[1], dtype = 'int32')\n",
    "    label_length = Input(name = 'label_length', shape = [1], dtype = 'int32')\n",
    "    loss = CTC('ctc',[y_pred, labels, input_length, label_length])\n",
    "    model = Model(inputs=[input_data, labels, label_length, input_length],\n",
    "                  outputs = loss)\n",
    "    model.summary()\n",
    "    # Build model here...\n",
    "\n",
    "    return model\n",
    "def pad_labels(labels, max_string_len):\n",
    "    padding = np.ones((labels.shape[0], max_string_len - labels.shape[1])) * -1\n",
    "    return np.concatenate((labels, padding), axis = 1)\n",
    "\n",
    "def train(model, x_train, y_train, label_len_train, input_len_train, batch_size=256, epochs=100, val_train_ratio=0.2):\n",
    "    max_string_len = 10\n",
    "    if y_train.shape[1] != max_string_len:\n",
    "        y_train = pad_labels(y_train, max_string_len)\n",
    "\n",
    "    adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=adam)\n",
    "    history = model.fit(x = {'the_input':x_train, 'the_labels':y_train, 'label_length':label_len_train,\n",
    "                             'input_length':input_len_train}, y = {'ctc': np.zeros([x_train.shape[0]])},\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_split=val_train_ratio,\n",
    "                        shuffle=True,\n",
    "                        verbose=1)\n",
    "\n",
    "    return history\n",
    "\n",
    "def read_data():\n",
    "    oh = OneHotEncoder()\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    x = list()\n",
    "    y = list()\n",
    "    t = list()\n",
    "    print(\"loading images...\")\n",
    "    for i, (img, words) in enumerate(load_data(DATA_PATH, verbose=False, framebyframe=False)):\n",
    "        if img.shape[0] != 75:\n",
    "            continue\n",
    "        x.append(img)\n",
    "        y.append(words)\n",
    "\n",
    "        t += words.tolist()\n",
    "        if i == 3:\n",
    "            break\n",
    "\n",
    "    t = le.fit_transform(t)\n",
    "    oh.fit(t.reshape(-1, 1))\n",
    "\n",
    "    print(\"convering to np array...\")\n",
    "    x = np.stack(x, axis=0)\n",
    "\n",
    "    print(\"transforming y...\")\n",
    "    for i in range(len(y)):\n",
    "        y_ = le.transform(y[i])\n",
    "        y[i] = np.asarray(oh.transform(y_.reshape(-1, 1)).todense())\n",
    "    y = np.stack(y, axis=0)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def main():\n",
    "    epochs = 100\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"loading data\")\n",
    "    x, y, label_len, input_len= load_data(DATA_PATH, verbose=True, num_samples=100, ctc_encoding=True)\n",
    "    end = time.time()\n",
    "\n",
    "    print(\"load data took\", end-start)\n",
    "    print(\"training data shapes:\", x.shape, y.shape)\n",
    "    x_train, x_test, y_train, y_test, label_len_train, label_len_test, \\\n",
    "    input_len_train, input_len_test = train_test_split(x, y, label_len, input_len, test_size=0.2)\n",
    "\n",
    "    model = build_model(x.shape[1:], 28, max_string_len = 10)\n",
    "\n",
    "    history = train(model, x_train, y_train, label_len_train, input_len_train, epochs=epochs)\n",
    "\n",
    "    print(\"Saving model...\")\n",
    "    model.save('model.h5')\n",
    "\n",
    "    # TODO: add visualization\n",
    "    print(\"Plotting...\")\n",
    "    #f, (ax1, ax2) = plt.subplots(2, 1)\n",
    "    #ax1.plot(range(1, epochs+1), history.history['val_acc'], 'tab:blue', label=\"validation accuracy\")\n",
    "    #ax1.plot(range(1, epochs+1), history.history['acc'], 'tab:red', label=\"training accuracy\")\n",
    "\n",
    "    #ax2.plot(range(1, epochs+1), history.history['loss'], 'tab:orange', label=\"loss\")\n",
    "    #ax2.plot(range(1, epochs+1), history.history['val_loss'], 'tab:green', label=\"validation loss\")\n",
    "\n",
    "    #ax1.legend()\n",
    "    #ax2.legend()\n",
    "\n",
    "    #f.savefig('training.png', dpi=300)\n",
    "    print(\"Done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
